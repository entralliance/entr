# Start from a core stack version
FROM jupyter/all-spark-notebook

# -------------------------------------------------------------------------------
# SECTION: initial setup & package updates
USER root
RUN apt-get update && \
    apt-get -y upgrade && \
    apt-get install -y libsasl2-modules-gssapi-heimdal && \
    apt-get install -y libsasl2-dev

## -------------------------------------------------------------------------------
## SECTION: Install and configure Python packages (including DBT)
USER jovyan
RUN conda install -c conda-forge sasl &&\
    pip install pandas matplotlib xgboost numpy sklearn xgboost sklearn scipy dbt-spark[PyHive]==1.0.0 sasl &&\
    mkdir /home/jovyan/.dbt -p

# copy profiles where dbt can find it
COPY profiles.yml /home/jovyan/.dbt

# TBD: Install and configure OpenOA - depends on how we want to do this based on workflow

## -------------------------------------------------------------------------------
## SECTION: copy local files and grant permissions
USER root

# grant permissions so that thrift server can create the metastore_db directory
RUN chmod g+w /usr/local/spark

# copy startup wrapper and grant exec permissions
COPY startup_wrapper_script.sh /usr/local/bin
RUN chmod +x /usr/local/bin/startup_wrapper_script.sh

# -------------------------------------------------------------------------------
# SECTION: Entry Point
USER root
WORKDIR /home/jovyan
CMD /usr/local/bin/startup_wrapper_script.sh
